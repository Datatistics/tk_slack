{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# template_engine\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp template_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from fastcore.basics import patch_to\n",
    "from fastcore.test import *\n",
    "from typing import List, Tuple, Dict, Any, Callable, Optional\n",
    "from tk_slack.core import ValueFormatter, DebugLogger, ColumnUtils, SlackFormatter\n",
    "from tk_slack.block_builder import BlockBuilder\n",
    "from tk_slack.interaction_builder import InteractionBuilder\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TemplateEngine:\n",
    "    \"\"\"\n",
    "    Core template engine for creating Slack messages from DataFrame data.\n",
    "    Provides methods to generate messages in different formats.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def _extract_interactive_options(self, row: pd.Series, col_map: Dict[str, str]) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Extract interactive option names and values from a row.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        col_map: Column name mapping (uppercase to original case)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (option_names, option_values)\n",
    "    \"\"\"\n",
    "    option_names = []\n",
    "    option_values = []\n",
    "    \n",
    "    # Check for option_name in case-insensitive manner\n",
    "    option_name_col = col_map.get('OPTION_NAME')\n",
    "    option_value_col = col_map.get('OPTION_VALUE')\n",
    "    \n",
    "    if option_name_col:\n",
    "        # Extract values\n",
    "        name_value = row[option_name_col] if option_name_col in row else None\n",
    "        \n",
    "        # Check if name_value is valid (not all NAs)\n",
    "        name_is_valid = False\n",
    "        if isinstance(name_value, (list, np.ndarray)) or (hasattr(name_value, '__iter__') and not isinstance(name_value, str)):\n",
    "            # For collections, check if any element is not NA\n",
    "            name_is_valid = any(pd.notna(v) for v in name_value) if name_value is not None else False\n",
    "        else:\n",
    "            # For scalar values, check directly\n",
    "            name_is_valid = pd.notna(name_value)\n",
    "        \n",
    "        if name_is_valid:\n",
    "            option_names = name_value\n",
    "            \n",
    "            # Get option values if column exists\n",
    "            if option_value_col:\n",
    "                value_value = row[option_value_col] if option_value_col in row else None\n",
    "                \n",
    "                # Check if value_value is valid (not all NAs)\n",
    "                value_is_valid = False\n",
    "                if isinstance(value_value, (list, np.ndarray)) or (hasattr(value_value, '__iter__') and not isinstance(value_value, str)):\n",
    "                    # For collections, check if any element is not NA\n",
    "                    value_is_valid = any(pd.notna(v) for v in value_value) if value_value is not None else False\n",
    "                else:\n",
    "                    # For scalar values, check directly\n",
    "                    value_is_valid = pd.notna(value_value)\n",
    "                \n",
    "                option_values = value_value if value_is_valid else ''\n",
    "            else:\n",
    "                option_values = ''\n",
    "            \n",
    "            # Convert to lists if they're not already\n",
    "            if not isinstance(option_names, list):\n",
    "                option_names = [str(option_names)]\n",
    "            \n",
    "            if not isinstance(option_values, list):\n",
    "                option_values = [str(option_values)] * len(option_names)\n",
    "            elif len(option_values) < len(option_names):\n",
    "                # Extend option_values if it's shorter than option_names\n",
    "                option_values = option_values + [str(option_values[-1])] * (len(option_names) - len(option_values))\n",
    "                \n",
    "    return option_names, option_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def _parse_row_config(self,row: pd.Series, view_config: Dict[str, Any], \n",
    "                         col_map: Dict[str, str]) -> Dict[str, Any]:\n",
    "        \"\"\"Parse row-specific configuration, falling back to view config.\n",
    "        \n",
    "        Args:\n",
    "            row: DataFrame row\n",
    "            view_config: View-level configuration\n",
    "            col_map: Column name mapping (uppercase to original case)\n",
    "            \n",
    "        Returns:\n",
    "            Merged configuration\n",
    "        \"\"\"\n",
    "        # Start with the view config\n",
    "        config = view_config.copy()\n",
    "        \n",
    "        # Check for row-specific config\n",
    "        if 'ROW_CONFIG' in col_map and pd.notna(row[col_map['ROW_CONFIG']]):\n",
    "            try:\n",
    "                row_config = row[col_map['ROW_CONFIG']]\n",
    "                if not isinstance(row_config, dict):    row_config = json.loads(row_config)\n",
    "                config.update(row_config)\n",
    "                return config\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                DebugLogger.log(f\"Error parsing row config. Using view_config.\")\n",
    "        \n",
    "        if 'CONFIG' in col_map and pd.notna(row[col_map['CONFIG']]):\n",
    "            try:\n",
    "                row_config = row[col_map['CONFIG']]\n",
    "                if not isinstance(row_config, dict): row_config = json.loads(row_config)\n",
    "                # Merge with view_config, with row_config taking precedence\n",
    "                config.update(row_config)\n",
    "                return config\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                DebugLogger.log(f\"Error parsing row config. Using view_config.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def _extract_meta_data_fields(self,row: pd.Series, df_columns: List[str], \n",
    "                                 config: Dict[str, Any]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Extract metadata fields from a row.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        df_columns: DataFrame column names\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        List of (label, value) tuples for metadata\n",
    "    \"\"\"\n",
    "    # Get metadata columns from config and columns ending with _meta\n",
    "    meta_data_cols = config.get('meta_data_cols', [])\n",
    "    meta_data_cols += [col for col in df_columns if col.lower().endswith('_meta')]\n",
    "    \n",
    "    meta_items = []\n",
    "    for col in meta_data_cols:\n",
    "        if col in df_columns:\n",
    "            # Check if the value is not NA - handle both scalar and array-like values\n",
    "            value = row[col]\n",
    "            \n",
    "            # For list-like values in Series, we need special handling\n",
    "            if isinstance(value, (list, np.ndarray)) or (hasattr(value, '__iter__') and not isinstance(value, str)):\n",
    "                is_valid = any(pd.notna(v) for v in value) if value is not None else False\n",
    "            else:\n",
    "                is_valid = pd.notna(value)\n",
    "                \n",
    "            if is_valid:\n",
    "                # Format the field name and value\n",
    "                field_name = col.lower().replace('_meta', '').replace('_', ' ').title()\n",
    "                field_value = ValueFormatter.format_value(value)\n",
    "                if field_value:\n",
    "                    meta_items.append((field_name, field_value))\n",
    "                \n",
    "    return meta_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def _extract_detail_fields(self, row: pd.Series, df_columns: List[str], \n",
    "                        config: Dict[str, Any]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Extract detail fields from a row.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        df_columns: DataFrame column names\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        List of (label, value) tuples for detail fields\n",
    "    \"\"\"\n",
    "    # Get detail columns from config or use default\n",
    "    detail_cols = config.get('detail_cols', [])\n",
    "    if not detail_cols:\n",
    "        # If not specified, use utility to get default detail columns\n",
    "        detail_cols = ColumnUtils.get_detail_columns(df_columns)\n",
    "    \n",
    "    field_items = []\n",
    "    for col in detail_cols:\n",
    "        # Split the condition to avoid the ambiguous truth value error\n",
    "        if col in df_columns:\n",
    "            value = row[col]\n",
    "            \n",
    "            # Check if value is not NA, handling different types appropriately\n",
    "            is_not_na = False\n",
    "            if isinstance(value, (list, np.ndarray)) or (hasattr(value, '__iter__') and not isinstance(value, str)):\n",
    "                # For collections, check if any value is not NA\n",
    "                is_not_na = any(pd.notna(v) for v in value) if value is not None else False\n",
    "            else:\n",
    "                # For scalar values, check directly\n",
    "                is_not_na = pd.notna(value)\n",
    "            \n",
    "            if is_not_na:\n",
    "                # Format field name and value for display\n",
    "                field_name = col.lower().replace('_', ' ').title()\n",
    "                field_value = ValueFormatter.format_value(value)\n",
    "                if field_value:\n",
    "                    field_items.append((field_name, field_value))\n",
    "                \n",
    "    return field_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def _extract_response_metadata(self,row: pd.Series, col_map: Dict[str, str],\n",
    "                                config: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"Extract metadata for action responses.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        col_map: Column name mapping\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Metadata string for action_id or None\n",
    "    \"\"\"\n",
    "    # Check for response_meta column\n",
    "    response_meta = None\n",
    "    \n",
    "    if 'RESPONSE_META' in col_map and pd.notna(row[col_map['RESPONSE_META']]):\n",
    "        response_meta = str(row[col_map['RESPONSE_META']])\n",
    "    elif 'response_meta' in config:\n",
    "        response_meta = str(config['response_meta'])\n",
    "        \n",
    "    # Add response config if specified\n",
    "    response_config = {}\n",
    "    \n",
    "    # Check for response type (ephemeral/in_channel)\n",
    "    if 'RESPONSE_TYPE' in col_map and pd.notna(row[col_map['RESPONSE_TYPE']]):\n",
    "        response_config['response_type'] = str(row[col_map['RESPONSE_TYPE']])\n",
    "    elif 'response_type' in config:\n",
    "        response_config['response_type'] = str(config['response_type'])\n",
    "        \n",
    "    # Check for response message template\n",
    "    if 'RESPONSE_MESSAGE' in col_map and pd.notna(row[col_map['RESPONSE_MESSAGE']]):\n",
    "        response_config['response_message'] = str(row[col_map['RESPONSE_MESSAGE']])\n",
    "    elif 'response_message' in config:\n",
    "        response_config['response_message'] = str(config['response_message'])\n",
    "        \n",
    "    # Check if should replace original message\n",
    "    if 'REPLACE_ORIGINAL' in col_map and pd.notna(row[col_map['REPLACE_ORIGINAL']]):\n",
    "        replace_val = row[col_map['REPLACE_ORIGINAL']]\n",
    "        response_config['replace_original'] = 'true' if replace_val else 'false'\n",
    "    elif 'replace_original' in config:\n",
    "        response_config['replace_original'] = str(config['replace_original']).lower()\n",
    "        \n",
    "    # If we have response config, encode it\n",
    "    if response_config:\n",
    "        # If we already have metadata, combine with response config\n",
    "        if response_meta:\n",
    "            # Convert existing metadata to dict if possible\n",
    "            try:\n",
    "                meta_dict = json.loads(response_meta) if isinstance(response_meta, str) else response_meta\n",
    "                if isinstance(meta_dict, dict):\n",
    "                    meta_dict.update(response_config)\n",
    "                    return json.dumps(meta_dict)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # If not valid JSON, use as is and append response config\n",
    "                combined = f\"{response_meta}|{json.dumps(response_config)}\"\n",
    "                return combined\n",
    "        else:\n",
    "            # Just use response config as metadata\n",
    "            return json.dumps(response_config)\n",
    "            \n",
    "    return response_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch_to(TemplateEngine,cls_method=True)\n",
    "def build_individual_message_blocks(cls, \n",
    "                                    row: pd.Series, \n",
    "                                    df_columns: List[str], \n",
    "                                    col_map: Dict[str, str], \n",
    "                                    config: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Build message blocks for a single row.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        df_columns: DataFrame column names\n",
    "        col_map: Column name mapping\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        List of Slack blocks for the message\n",
    "    \"\"\"\n",
    "    # Initialize blocks for this message\n",
    "    payload_blocks = []\n",
    "    \n",
    "    # 1. Title Section - Use SlackFormatter for title with proper linking\n",
    "    section_text = SlackFormatter.format_section_name(row, df_columns)\n",
    "    payload_blocks.append(BlockBuilder.create_section_block(section_text))\n",
    "    \n",
    "    # 2. Description Text - Look for TEXT or DESCRIPTION column\n",
    "    for text_col in ['TEXT', 'DESCRIPTION']:\n",
    "        if text_col in col_map and pd.notna(row[col_map[text_col]]):\n",
    "            payload_blocks.append(\n",
    "                BlockBuilder.create_section_block(str(row[col_map[text_col]]))\n",
    "            )\n",
    "            break\n",
    "    \n",
    "    # 3. Metadata - Get and format metadata fields\n",
    "    meta_items = cls._extract_meta_data_fields(row, df_columns, config)\n",
    "    \n",
    "    # Note: We don't need to add view information to visible metadata anymore\n",
    "    # since we're using Slack's metadata field for that information now\n",
    "    \n",
    "    if meta_items:\n",
    "        meta_block = BlockBuilder.create_metadata_context(meta_items)\n",
    "        if meta_block:\n",
    "            payload_blocks.append(meta_block)\n",
    "    \n",
    "    # 4. Detail Fields - Get and format detail fields\n",
    "    field_items = cls._extract_detail_fields(row, df_columns, config)\n",
    "    if field_items:\n",
    "        field_blocks = BlockBuilder.create_fields_section(field_items)\n",
    "        payload_blocks.extend(field_blocks)\n",
    "    \n",
    "    # 5. Interactive Elements\n",
    "    option_names, option_values = cls._extract_interactive_options(row, col_map)\n",
    "    \n",
    "    if option_names:\n",
    "        action_type = config.get('action_type', None)\n",
    "        \n",
    "        # Extract response config for interactive elements\n",
    "        response_config = {\n",
    "            \"response_type\": config.get(\"response_type\", \"ephemeral\"),\n",
    "            \"response_message\": config.get(\"response_message\", \"Thank you for your response!\"),\n",
    "            \"replace_original\": config.get(\"replace_original\", False)\n",
    "        }\n",
    "        \n",
    "        # We'll no longer need to pass metadata to interactive elements\n",
    "        # since we're using Slack's metadata field - pass basic info for debugging only\n",
    "        debug_metadata = {\"source\": \"data_alert\"}\n",
    "        \n",
    "        # Use the view name for action_id base\n",
    "        elements = InteractionBuilder.detect_and_create_interactive_elements(\n",
    "            option_names, option_values, action_type, debug_metadata\n",
    "        )\n",
    "        \n",
    "        if elements:\n",
    "            payload_blocks.append(\n",
    "                InteractionBuilder.create_actions_block(elements)\n",
    "            )\n",
    "    \n",
    "    # 6. Add a divider at the end\n",
    "    payload_blocks.append(BlockBuilder.create_divider())\n",
    "    \n",
    "    return payload_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
